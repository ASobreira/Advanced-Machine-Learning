{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, matthews_corrcoef, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.special import softmax\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for classification metrics + confusion matrix\n",
    "def report (y_test, preds):\n",
    "    stats = pd.DataFrame()  \n",
    "    stats['Precision'] = [precision_score(y_test, preds)] \n",
    "    stats['Recall'] = [recall_score(y_test, preds)]\n",
    "    stats['F1'] = [f1_score(y_test, preds)]\n",
    "    stats['Matthews'] = [matthews_corrcoef(y_test, preds)]\n",
    "    stats['Accuracy'] = [accuracy_score(y_test, preds)]\n",
    "    display(stats)\n",
    "    display(pd.DataFrame(confusion_matrix(y_test, preds), columns=['PP', 'PN'], index=['P', 'N']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Implement a Weighted Average Ensemble System in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data\n",
    "df = datasets.load_breast_cancer()\n",
    "y = df.target\n",
    "X = df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nº of 1's = 357\n",
      "nº of 0's = 212\n"
     ]
    }
   ],
   "source": [
    "print(\"nº of 1's = \" + str((df[\"target\"] == 1).sum()))\n",
    "print(\"nº of 0's = \" + str((df[\"target\"] == 0).sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set seems to be unabalanced\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Procedure:\n",
    "1) split and scale data:\n",
    "    - split train / validation\n",
    "    - split train once more to obtain test set\n",
    "    - scale\n",
    "2) train each expert on train set\n",
    "    - predict with validation to get each accuracy\n",
    "    apply soft max formula to each accuracy to  get the weights \n",
    "4) predict experts with test set\n",
    "    - aply dot prod to this preds and weights\n",
    "5) compare with the true labels to get the accuracy of the ensembled\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This process will be divided into 3 main phases for a better organizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st split of Data: To obtain last preds - last phase - (test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=222)\n",
    "#2nd split of Data: For training and obtain 1st preds to get weights with softmax - first phase - (validation)\n",
    "X_train_01, X_valid, y_train_01, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit a scaler to the training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_01)\n",
    "# Lets transform the X's\n",
    "X_train_01 = scaler.transform(X_train_01)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training some experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "dt_gini = DecisionTreeClassifier(criterion=\"gini\").fit(X_train_01, y_train_01) # critierion = Gini\n",
    "dt_entropy = DecisionTreeClassifier(criterion=\"entropy\").fit(X_train_01, y_train_01) # critierion = entropy\n",
    "# Support Vector Machine\n",
    "svc_rbf = SVC(kernel = \"rbf\").fit(X_train_01, y_train_01) # kernel = RBF\n",
    "svc_poly = SVC(kernel = \"poly\").fit(X_train_01, y_train_01) # kernel = poly\n",
    "# Logistic Regression\n",
    "logreg_default = LogisticRegression(C = 1.0, max_iter = 10000).fit(X_train_01, y_train_01) # C = 1.0\n",
    "logreg_C = LogisticRegression(C=.01,max_iter = 10000).fit(X_train_01, y_train_01) # C = .01\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the experts trained we are going to obtain the predictions and accuracys using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt_gini, dt_entropy, svc_rbf, svc_poly, logreg_default, logreg_C]\n",
    "\n",
    "def pred_acc(models, data, labels, pred=False, acc=False, mcc=False):\n",
    "    accuracy_scores = []\n",
    "    predictions = []\n",
    "    mcc_scores = []\n",
    "    \n",
    "    # loop through various experts obtaining predictions and accuracies\n",
    "    for model in models:\n",
    "        preds_model = model.predict(data)\n",
    "        accuracy_model = accuracy_score(labels, preds_model)\n",
    "        mcc_model = matthews_corrcoef(labels, preds_model)\n",
    "        predictions.append(preds_model)\n",
    "        accuracy_scores.append(accuracy_model)\n",
    "        mcc_scores.append(mcc_model)\n",
    "    \n",
    "    if pred:\n",
    "        return predictions\n",
    "    elif acc:\n",
    "        return accuracy_scores\n",
    "    elif mcc:\n",
    "        return mcc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9252336448598131,\n",
       " 0.9158878504672897,\n",
       " 0.9813084112149533,\n",
       " 0.9158878504672897,\n",
       " 0.9813084112149533,\n",
       " 0.9719626168224299]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list with the fited models\n",
    "models = [dt_gini, dt_entropy, svc_rbf, svc_poly, logreg_default, logreg_C]\n",
    "\n",
    "# Get Accuracys\n",
    "acc = pred_acc(models, X_valid, y_valid, pred = False, acc = True, mcc = False)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The next step is to obtain the weights corresponding to each expert using softmax function: \n",
    "    - $ g_k = \\frac{ exp(\\mu_k) }{ \\sum\\limits_{j=1}^{K}exp(\\mu_j) }, k = 1,2,...,K $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16274487, 0.16123097, 0.17213147, 0.16123097, 0.17213147,\n",
       "       0.17053025])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (np.exp(acc)/np.sum(np.exp(acc)))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Model  Accuracy of experts   Weights\n",
      "2                                        SVC()             0.981308  0.172131\n",
      "4           LogisticRegression(max_iter=10000)             0.981308  0.172131\n",
      "5   LogisticRegression(C=0.01, max_iter=10000)             0.971963  0.170530\n",
      "0                     DecisionTreeClassifier()             0.925234  0.162745\n",
      "1  DecisionTreeClassifier(criterion='entropy')             0.915888  0.161231\n",
      "3                           SVC(kernel='poly')             0.915888  0.161231\n"
     ]
    }
   ],
   "source": [
    "accuracys = acc\n",
    "weights = weights\n",
    "models \n",
    "\n",
    "df = pd.DataFrame({'Model': models, 'Accuracy of experts': accuracys, 'Weights': weights})\n",
    "df_sorted_acc = df.sort_values(by='Accuracy of experts', ascending=False)\n",
    "print(df_sorted_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can observe that the highest weight is atributed to the expert with the highest accuracy value, in this case SVC with rbf kernel and and logistic regression with C = 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3th phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- obtain new preds from experts this time with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pred_acc(models, X_test, y_test, pred = True, mcc = False, acc= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need to make a dot product between the test set predictions and and weights obtained with softmax\n",
    "    - Given a set of experts {f1, f2, . . . , fn}, with accuracy scores {a1, a2, . . . , an}, and input X, the\n",
    "output of the system becomes:\n",
    "        - round(softmax([a1, a2, . . . , an]) · [f1(X), f2(X), . . . , fn(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the final predicionts: [1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Get new preds with dot product, rounded values\n",
    "final_preds = np.round(np.dot(weights, test_preds))\n",
    "print(\"This are the final predicionts: \" + str(final_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The final step is to evaluate the quality of the ensembled model. To do this we will compare the \"final_preds\" with the true labels and get classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Matthews</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.967033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98324</td>\n",
       "      <td>0.956183</td>\n",
       "      <td>0.979021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision  Recall       F1  Matthews  Accuracy\n",
       "0   0.967033     1.0  0.98324  0.956183  0.979021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP</th>\n",
       "      <th>PN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PP  PN\n",
       "P  52   3\n",
       "N   0  88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(y_test, final_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as we saw in the begining the dataset can be considered unbalanced (nº of 1's = 357; nº of 0's = 212) so we will compare the matthews_corrcoef which is a more adequate measure for the model quality, given this type of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Ensembled model MCC = 0.970681\n",
      "                                         Model  MCC of expert models\n",
      "4           LogisticRegression(max_iter=10000)              0.962130\n",
      "2                                        SVC()              0.961119\n",
      "5   LogisticRegression(C=0.01, max_iter=10000)              0.942645\n",
      "0                     DecisionTreeClassifier()              0.846285\n",
      "3                           SVC(kernel='poly')              0.832595\n",
      "1  DecisionTreeClassifier(criterion='entropy')              0.825856\n",
      "\n",
      "                                Ensembled model Accuracy = 0.986014\n",
      "                                         Model  Accuracy of experts\n",
      "2                                        SVC()             0.981308\n",
      "4           LogisticRegression(max_iter=10000)             0.981308\n",
      "5   LogisticRegression(C=0.01, max_iter=10000)             0.971963\n",
      "0                     DecisionTreeClassifier()             0.925234\n",
      "1  DecisionTreeClassifier(criterion='entropy')             0.915888\n",
      "3                           SVC(kernel='poly')             0.915888\n"
     ]
    }
   ],
   "source": [
    "# matthews_corrcoef for experts\n",
    "mcc_experts = pred_acc(models, X_valid, y_valid, pred = False, acc = False, mcc = True)\n",
    "\n",
    "experts_mcc = mcc_experts\n",
    "models \n",
    "\n",
    "# Dataframes with MCC and ACC for Experts\n",
    "df = pd.DataFrame({'Model': models, 'MCC of expert models': experts_mcc})\n",
    "df_sorted_mcc = df.sort_values(by='MCC of expert models', ascending=False)\n",
    "print(\"                                      Ensembled model MCC = 0.970681\")\n",
    "print(df_sorted_mcc)\n",
    "print(\"\")\n",
    "print(\"                                Ensembled model Accuracy = 0.986014\")\n",
    "print(df_sorted_acc[[\"Model\", \"Accuracy of experts\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the model with the highest matthews_corrcoef value is the Logistic Regression (Default) with 0.962130 which is samler than the obtained with the ensembled model, 0.970681.\n",
    "- the model with the highest accuracy value is the Support vector machine (Default) with 0.981308 which is samler than the obtained with the ensembled model, 0.986014\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- It is possible to observe that by using a divide and conquer principle with just six experts, both metrics, accuracy and the matthews_corrcoef, which is a more adequate measure of the quality of this dataset given that is unbalanced, were higher when compared with the ones from each of the individuals models.\n",
    "- Besides better metrics, another advantadge of using ensembled average models is that a model with lower variance is obtained, reducing the risk of overfitng when compared with a single model.\n",
    "- One possible disavantage of this type of models is conected with the fact that the accuracy level of the emsembled model is derived from a weighted average which may leed to a  loss of  interpretation capability given that we cannot obtain the original values.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
