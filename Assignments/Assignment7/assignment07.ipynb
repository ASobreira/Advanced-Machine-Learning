{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "- by Martim Silva 51304 and Alexandre Sobreira 59451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_func(nrEpochs, lag, X, y):\n",
    "\n",
    "    ## LSTM Model\n",
    "    lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer((lag,1)),    # The input layer will be lag\n",
    "    tf.keras.layers.LSTM(10),  # Since we have an imput of 12 it doesnt make sence to use higher than that # trocar par DENSE\n",
    "    tf.keras.layers.Dense(1, activation=\"tanh\"), # Since I want to predict 1 value I want to output 1!\n",
    "    ])\n",
    "    \n",
    "    ## Compile\n",
    "    lstm_model.compile(optimizer = \"Adam\", loss = \"mse\")\n",
    "\n",
    "    ##Adapt X\n",
    "    X_lstm = np.expand_dims(X, axis = 2)\n",
    "\n",
    "    ## 1st split\n",
    "    print(\"Training with first 2400 and testing with 2401 to 2500\")\n",
    "    X_lstm_train = X_lstm[:2400]\n",
    "    y_lstm_train = y[:2400]\n",
    "    ### fit \n",
    "    lstm_model.fit(X_lstm_train, y_lstm_train, batch_size=1, epochs=nrEpochs, shuffle=False)\n",
    "    ### pred\n",
    "    X_lstm_pred = X_lstm[2401:2501]\n",
    "    y_pred = lstm_model.predict(X_lstm_pred)\n",
    "    print(mean_squared_error(y[2401:2501], y_pred))\n",
    "\n",
    "    ## 2nd split and fit\n",
    "    print(\"Training with 2401 to 4900 and testing with 4901 to 5000\")\n",
    "    lstm_model.fit(X_lstm[2401:4900], y[2401:4900], batch_size=1, epochs=nrEpochs, shuffle=False)\n",
    "    ###pred\n",
    "    y_pred = lstm_model.predict(X_lstm[4901:])\n",
    "    print(mean_squared_error(y[4901:], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftlfn_func(nrEpochs, lag, X, y): \n",
    "    \n",
    "    ## FTLFN Model\n",
    "    ftlf_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_dim=X.shape[1]),    \n",
    "    tf.keras.layers.Dense(1),  \n",
    "    ])\n",
    "    \n",
    "    ## Compile\n",
    "    ftlf_model.compile(optimizer = \"Adam\", loss = \"mse\")\n",
    "\n",
    "    ##Adapt X\n",
    "    X = np.expand_dims(X, axis = 2)\n",
    "    y = np.array(y)\n",
    "\n",
    "    ## 1st split\n",
    "    print(\"Training with first 2400 and testing with 2401 to 2500\")\n",
    "    X_fltf_train = X[:2400]\n",
    "    y_fltf_train = y[:2400]\n",
    "    ### fit \n",
    "    ftlf_model.fit(X_fltf_train, y_fltf_train, batch_size=1, epochs=nrEpochs, shuffle=False)\n",
    "    ### pred\n",
    "    X_fltf_pred = X[2401:2501]\n",
    "    y_pred = ftlf_model.predict(X_fltf_pred)\n",
    "    y_pred = np.array(y_pred)\n",
    "    print(mean_squared_error(y[2401:2501], y_pred))\n",
    "\n",
    "\n",
    "    ## 2nd split and fit\n",
    "    print(\"Training with 2401 to 4900 and testing with 4901 to 5000\")\n",
    "    ftlf_model.fit(X[2401:4900], y[2401:4900], batch_size=1, epochs=nrEpochs, shuffle=False)\n",
    "    ###pred\n",
    "    y_pred = ftlf_model.predict(X[4901:])\n",
    "    print(mean_squared_error(y[4901:], y_pred))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to use the sin function\n",
    "# First I need to generate the x\n",
    "periods = 100\n",
    "lag = 12\n",
    "points_per_period = 50\n",
    "data = np.sin(np.linspace(0,2*np.pi*periods, num=periods*points_per_period)) #This is my x, it will be my angles, 0 to pi.\n",
    "data                                                                         #it will creat equaly size spaces between 0 and .. (linspace)\n",
    "                                                                            #and I apply the sin...\n",
    "                                                                            # \n",
    "                                                                            # # lets add the lag\n",
    "\n",
    "\n",
    "## Adapt Data for Time series \n",
    "X, y = [], []\n",
    "for i in range(lag, data.shape[0]-1):\n",
    "    X.append(data[i-lag:i]) # we getting 12 sample. My x will have 4000 samples each with 12 instances\n",
    "    y.append(data[i])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The sin function gave me the complete signal. But we need to adapt for this problem\\\n",
    " To make predictions we need to to have several windows.\\\n",
    " We consturct a data set  which has 12 datapoints and the label. Fazemos um shift de 12 em 12.\\\n",
    " it says we need to use a filter of 12 (we are going to observe the 12 and predict the next 1). Then we shift again and so one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) no noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOr this type of problem, since we are comparing values, the MSE is the best lost function, for images would be the cross entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe fit shuffles by default and we dont want that, we want to preserva the order. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network needs to \"warm up\" to find the direction of the gradient. This will have  a huge impact on the MSE this  to pass the "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with first 2400 and testing with 2401 to 2500\n",
      "Epoch 1/2\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.0637\n",
      "Epoch 2/2\n",
      "2400/2400 [==============================] - 11s 4ms/step - loss: 0.0048\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "0.005339741994797782\n",
      "Training with 2401 to 4900 and testing with 4901 to 5000\n",
      "Epoch 1/2\n",
      "2499/2499 [==============================] - 12s 5ms/step - loss: 0.0026\n",
      "Epoch 2/2\n",
      "2499/2499 [==============================] - 11s 4ms/step - loss: 0.0018\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "0.001554377941643515\n"
     ]
    }
   ],
   "source": [
    "lstm_func(2, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTLFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with first 2400 and testing with 2401 to 2500\n",
      "Epoch 1/2\n",
      "2400/2400 [==============================] - 5s 2ms/step - loss: 0.0460\n",
      "Epoch 2/2\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.0039\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "0.00045505211296543064\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[277], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ftlfn_func(\u001b[39m2\u001b[39;49m, lag, X, y)\n",
      "Cell \u001b[1;32mIn[276], line 30\u001b[0m, in \u001b[0;36mftlfn_func\u001b[1;34m(nrEpochs, lag, X, y)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(mean_squared_error(y[\u001b[39m2401\u001b[39m:\u001b[39m2501\u001b[39m], y_pred))\n\u001b[0;32m     29\u001b[0m accuracy_combined \u001b[39m=\u001b[39m history_full\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 30\u001b[0m al_accuracy_combined \u001b[39m=\u001b[39m history_full\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m]    \n\u001b[0;32m     32\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39m2\u001b[39m, accuracy_combined, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39m2\u001b[39m, al_accuracy_combined, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "ftlfn_func(2, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) with noise by adding a Gaussian N(0, 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add ao data o gaussian noise! (np.random(loc=0,scale (0.05, size = data[shape[0]])))\n",
    "# I need to use the sin function\n",
    "# First I need to generate the x\n",
    "periods = 100\n",
    "lag = 12\n",
    "points_per_period = 50\n",
    "data = np.sin(np.linspace(0,2*np.pi*periods, num=periods*points_per_period)) #This is my x, it will be my angles, 0 to pi.\n",
    "                                                                         #it will creat equaly size spaces between 0 and .. (linspace)\n",
    "                                                                            #and I apply the sin...\n",
    "                                                                            # \n",
    "                                                                            # # lets add the lag\"\"\"\n",
    "                                                                            \n",
    "                                                                    \n",
    "data = np.random.normal(loc=0, scale=0.05, size=data.shape[0])\n",
    "\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(lag, data.shape[0]-1):\n",
    "    X.append(data[i-lag:i]) # we getting 12 sample. My x will have 4000 samples each with 12 instances\n",
    "    y.append(data[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_func(1, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTLFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftlfn_func(1, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrEpochs = 50\n",
    "\n",
    "alpha_one = 0.6\n",
    "alpha_two = -0.54\n",
    "alpha_three = -0.44\n",
    "data = [5,6,3]\n",
    "nr_datapoints = 5000\n",
    "X, y = [], []\n",
    "\n",
    "#(np.random(loc=0,scale (0.01, size = data[shape[0]])))\n",
    "\n",
    "for i in range(nr_datapoints-3):\n",
    "    data.append(alpha_one*data[i+2]\n",
    "    + alpha_two*data[i+1]\n",
    "    + alpha_three*data[i])\n",
    "\n",
    "for i in range(lag, len(data)-1):\n",
    "    X.append(data[i-lag:i]) # we getting 12 sample. My x will have 4000 samples each with 12 instances\n",
    "    y.append(data[i])\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) no noise, clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_func(nrEpochs, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTLFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftlfn_func(nrEpochs, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) with noise by adding a Gaussian noise N(0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add the lag\n",
    "alpha_one = 0.6\n",
    "alpha_two = -0.54\n",
    "alpha_three = -0.44\n",
    "data = [5,6,3]\n",
    "nr_datapoints = 5000\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(nr_datapoints-3):\n",
    "    data.append(alpha_one*data[i+2]\n",
    "    + alpha_two*data[i+1]\n",
    "    + alpha_three*data[i] + 0.01)\n",
    "\n",
    "for i in range(lag, len(data)-1):\n",
    "    X.append(data[i-lag:i]) # we getting 12 sample. My x will have 4000 samples each with 12 instances\n",
    "    y.append(data[i])\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_func(nrEpochs, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTLFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftlfn_func(nrEpochs, lag, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
